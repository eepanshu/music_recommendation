 {
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**[Using Machine Learning to Recommend Songs](https://www.sciencebuddies.org/science-fair-projects/project_ideas/ArtificialIntelligence_p012/artificial-intelligence/K-Means_Spotify)**\n",
        "\n",
        "This notebook was developed by Science Buddies [www.sciencebuddies.org](https://www.sciencebuddies.org/) as part of a science project to allow students to explore and learn about artificial intelligence. For personal use, this notebook can be downloaded and modified with attribution. For all other uses, please see our [Terms and Conditions of Fair Use](https://www.sciencebuddies.org/about/terms-and-conditions-of-fair-use).  \n",
        "\n",
        "**Troubleshooting tips**\n",
        "*   Read the written instructions at Science Buddies and the text and comments on this page carefully.\n",
        "*   If you make changes that break the code, you can download a fresh copy of this notebook and start over.\n",
        "\n",
        "*   If you are using this notebook for a science project and need help, visit our [Ask an Expert](https://www.sciencebuddies.org/science-fair-projects/ask-an-expert-intro) forum for assistance."
      ],
      "metadata": {
        "id": "fGEvQQapSl-D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **How To Use This Notebook**\n",
        "\n",
        "This notebook contains text fields, like this one, that give you information about the project and instructions."
      ],
      "metadata": {
        "id": "tF0yOivrSrBJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRJ0yAyxSdng"
      },
      "outputs": [],
      "source": [
        "# There are also code blocks, like this one.\n",
        "\n",
        "# The green text in a code block are comments. Comments are descriptions of what the code does.\n",
        "\n",
        "# The non-green text in a code block is the Python code. Click on the triangle in the top left corner to run this code block.\n",
        "\n",
        "print(\"Congratulations, you ran a code block! Try changing the text in the code and running it again.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Importing Libraries**\n",
        "We will start this science project by importing some necessary libraries. These libraries contain functions that we will be using to create and display our maze. The comments tell you what each libary is for."
      ],
      "metadata": {
        "id": "-02hIAGwSuKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This library provides support for working with arrays and matrices, along with various mathematical functions\n",
        "# to operate on these arrays\n",
        "import numpy as np\n",
        "\n",
        "# Pandas is a powerful data manipulation and analysis library. It provides data structures like DataFrames and\n",
        "# Series that allow for easy data handling and analysis\n",
        "import pandas as pd\n",
        "\n",
        "# This is part of the scikit-learn library and is used to perform K-means clustering, an unsupervised machine\n",
        "# learning algorithm that groups similar data points into clusters.\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Matplotlib is a widely used plotting library in Python. The \"pyplot\" submodule provides functions to create various\n",
        "# types of plots and visualizations\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Another part of scikit-learn, PCA (Principal Component Analysis) is used for dimensionality reduction. It helps\n",
        "# transform high-dimensional data into a lower-dimensional representation while preserving as much of the variance as possible.\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pd.set_option(\"display.max_columns\", None)    # Sets the maximum number of columns to be displayed in a Pandas DataFrame to be unlimited\n",
        "pd.set_option(\"display.max_rows\", None)       # Sets the maximum number of rows to be displayed in a Pandas DataFrame to be unlimited\n",
        "pd.set_option(\"display.width\", None)          # Sets the maximum width of the display for a Pandas DataFrame to be unlimited\n",
        "pd.set_option(\"display.max_colwidth\", None)   # Sets the maximum width of column contents to be unlimited, allowing for complete display of text data\n",
        "\n",
        "print(\"You have imported all the libraries.\")"
      ],
      "metadata": {
        "id": "f4gB0giqStb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Data into a Pandas DataFrame"
      ],
      "metadata": {
        "id": "UERTw4criZmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV file into a pandas DataFrame\n",
        "df = pd.read_csv(\"https://www.sciencebuddies.org/ai/colab/spotify.csv?t=AQX3FN5n47RYT9PqwsfVEk9Iuje0qM8M3qwo6EMrO_NZpw\")\n",
        "\n",
        "# We can see what the dataframe looks like by using the head function\n",
        "df.head()"
      ],
      "metadata": {
        "id": "ZhxQCP2WiaDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing the Dataset"
      ],
      "metadata": {
        "id": "p33Ot2Alidoi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropping NaN Values"
      ],
      "metadata": {
        "id": "Mue8C8YOBE51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the shape before dropping NaN values\n",
        "print(\"Shape before dropping NaN values:\", df.shape)\n",
        "\n",
        "# Drop NaN values from the DataFrame\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Display the shape after dropping NaN values\n",
        "print(\"Shape after dropping NaN values:\", df.shape)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "qFAaMkQailt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropping Features"
      ],
      "metadata": {
        "id": "NWXdRqSNBHGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: List the columns that you want to drop\n",
        "columns_to_drop = ['Artist']\n",
        "\n",
        "# Create a new DataFrame that excludes the specified columns\n",
        "dropped_df = df.drop(columns=columns_to_drop)\n",
        "\n",
        "# Let's check if our specified columns are no longer there!\n",
        "dropped_df.head()"
      ],
      "metadata": {
        "id": "0IwtY0Xfifd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since KMeans is a distance-based algorithm, it is crucial to normalize or scale the features to ensure that all features contribute equally to the distance calculations."
      ],
      "metadata": {
        "id": "J7lJSUOXjP0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can use the describe() function to provide a summary of statistical information about the numerical columns in the DataFrame\n",
        "dropped_df.describe()"
      ],
      "metadata": {
        "id": "iHue1OKXjQtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Identify the numerical feature columns you want to normalize\n",
        "numerical_columns = ['Loudness']\n",
        "\n",
        "# Create a copy of the dropped_df\n",
        "final_df = dropped_df\n",
        "\n",
        "# Apply min-max scaling to the selected numerical feature columns\n",
        "final_df[numerical_columns] = (dropped_df[numerical_columns] - dropped_df[numerical_columns].min()) / (dropped_df[numerical_columns].max() - dropped_df[numerical_columns].min())\n",
        "\n",
        "# Let's see what our normalization did!\n",
        "final_df.describe()"
      ],
      "metadata": {
        "id": "ER1smI68jUH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clustering the Data"
      ],
      "metadata": {
        "id": "Y-lEuLmhjVqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function that works out optimum number of clusters\n",
        "def optimise_k_means(data, max_k):\n",
        "    means = []\n",
        "    inertias = []\n",
        "\n",
        "    for k in range(1, max_k+1):\n",
        "        kmeans = KMeans(n_clusters=k, n_init=max_k)\n",
        "        kmeans.fit(data)\n",
        "\n",
        "        means.append(k)\n",
        "        inertias.append(kmeans.inertia_)\n",
        "\n",
        "    # Generate the elbow plot\n",
        "    plt.figure(figsize=(10, 5))  # Create a new figure\n",
        "    plt.plot(means, inertias, 'o-')\n",
        "    plt.xlabel('Number of Clusters')\n",
        "    plt.ylabel('Inertia')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "print(\"This code block has been run and the optimise_k_means() function is now available for use.\")"
      ],
      "metadata": {
        "id": "1Z1C_LkgjZPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimise_k_means(final_df, 10)"
      ],
      "metadata": {
        "id": "sZAGgmv1jcBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applying K-Means Clustering"
      ],
      "metadata": {
        "id": "2gsd_qfrjezP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a KMeans model with 4 clusters\n",
        "kmeans = KMeans(n_clusters= , n_init='auto') # TODO: Insert number of clusters\n",
        "\n",
        "# Fit the KMeans model to the data in 'final_df'\n",
        "kmeans.fit(final_df)\n",
        "\n",
        "# Assign cluster labels to each data point and add the 'Cluster' column to the original DataFrame\n",
        "df['Cluster'] = kmeans.labels_\n",
        "final_df['Cluster'] = kmeans.labels_\n",
        "\n",
        "# Let's check out what our DataFrame looks like now!\n",
        "df.head()"
      ],
      "metadata": {
        "id": "JmKZ9sITjgkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize the Model"
      ],
      "metadata": {
        "id": "iu1yvl_4jkDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform PCA for dimensionality reduction\n",
        "pca = PCA(n_components=2)\n",
        "reduced_features = pca.fit_transform(final_df.drop('Cluster', axis=1)) # Exclude the cluster labels\n",
        "\n",
        "# Add the reduced components to the DataFrame\n",
        "final_df['pca_1'] = reduced_features[:, 0]\n",
        "final_df['pca_2'] = reduced_features[:, 1]\n",
        "\n",
        "# Create a scatter plot\n",
        "plt.scatter(final_df['pca_1'], final_df['pca_2'], c=final_df['Cluster'], cmap='viridis')\n",
        "plt.title('KMeans Clustering Results using PCA')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5Cd1NT2ZjmQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Our Song Recommendation Function"
      ],
      "metadata": {
        "id": "8DT3T8r-jpFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This function attemps to find the index of a given track name in the 'Track' column of the dataframe\n",
        "def find_track_index(track_name, df):\n",
        "    try:\n",
        "        # Attempt to find the index of the first occurence of 'track_name' in the 'Track' column of 'df'\n",
        "        track_index = df[df['Track'] == track_name].index[0]\n",
        "        # Return the index if found\n",
        "        return track_index\n",
        "    except IndexError:\n",
        "        # If the track name is not found, return None\n",
        "        return None"
      ],
      "metadata": {
        "id": "jH2ChCFtjqu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This function finds song recommendations based on a given track name and the DataFrame 'df'\n",
        "def find_song_recommendation(track_name, df):\n",
        "    # Call the 'find_track_index' function to get the index of the provided 'track_name'\n",
        "    track_index = find_track_index(track_name, df)\n",
        "\n",
        "    # Retrieve the cluster label of the provided track using its index\n",
        "    cluster = df.loc[track_index]['Cluster']\n",
        "\n",
        "    # Create a filter to select rows in 'df' that belong to the same cluster as the provided track\n",
        "    filter = (df['Cluster'] == cluster)\n",
        "\n",
        "    # Apply the filter to 'df' to get a DataFrame containing songs from the same cluster\n",
        "    filtered_df = df[filter]\n",
        "\n",
        "    # Generate song recommendations by randomly selecting tracks from the same cluster\n",
        "    for i in range(5):\n",
        "        # Randomly sample a track from the shuffled DataFrame\n",
        "        recommendation = filtered_df.sample()\n",
        "        # Print the recommended track's title and artist\n",
        "        print(recommendation.iloc[0]['Track'] + ' by ' + recommendation.iloc[0]['Artist'])"
      ],
      "metadata": {
        "id": "l1gt2F2AjsL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Experiment with inputting different song names!\n",
        "find_song_recommendation('Clint Eastwood', df)"
      ],
      "metadata": {
        "id": "7OjNJhwBju-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Our Song Randomizer Function"
      ],
      "metadata": {
        "id": "Mna-TJVdjxUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_random_song(track_name, df):\n",
        "    # Call the 'find_track_index' function to get the index of the provided 'track_name'\n",
        "    track_index = find_track_index(track_name, df)\n",
        "\n",
        "    # Retrieve the cluster label of the provided track using its index\n",
        "    cluster = df.loc[track_index]['Cluster']\n",
        "\n",
        "    # Create a filter to select rows in 'df' that don't belong to the same cluster as the provided track\n",
        "    filter = (df['Cluster'] != cluster)\n",
        "\n",
        "    # Apply the filter to 'df' to get a DataFrame containing songs from different clusters\n",
        "    filtered_df = df[filter]\n",
        "\n",
        "    # Generate song recommendations by randomly selecting tracks from the filtered dataframe\n",
        "    for i in range(5):\n",
        "        # Randomly sample a track from the shuffled DataFrame\n",
        "        random_song = filtered_df.sample()\n",
        "        # Print the random song track's title and artist\n",
        "        print(random_song.iloc[0]['Track'] + ' by ' + random_song.iloc[0]['Artist'])"
      ],
      "metadata": {
        "id": "vhVytgsKjx7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Experiment with inputting different song names!\n",
        "find_random_song('Blue Flame', df)"
      ],
      "metadata": {
        "id": "f5e4H19pj0UL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the Model"
      ],
      "metadata": {
        "id": "l_TySQm6j1cO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Insert the accuracies for each of the functions\n",
        "recommendations_accuracy = []\n",
        "random_songs_accuracy = []\n",
        "\n",
        "recommendations_average = sum(recommendations_accuracy) / len(recommendations_accuracy)\n",
        "random_songs_average = sum(random_songs_accuracy) / len(random_songs_accuracy)\n",
        "\n",
        "print(\"Recommendations average accuracy:\", recommendations_average)\n",
        "print(\"Random songs average accuracy:\", random_songs_average)"
      ],
      "metadata": {
        "id": "_2NH5NLGj4GO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
